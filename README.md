# VisionExplainr
AI that explains whatâ€™s happening inside a video in plain English â€” step-by-step.

ğŸ¯ Goal

Computer Vision + LLM = Scene-by-scene description generator.

ğŸ’¡ Use Case

Video analytics, sports, CCTV interpretation, or accessibility for the visually impaired.

ğŸ§© Architecture

Frame Extraction (1 frame/sec)

Action Recognition (e.g., YOLO + DeepSORT)

Event Detection (goal, jump, run, fight, etc.)

LLM Commentary Generation

Audio Narration (TTS).

âš™ï¸ Tech Stack

OpenCV, YOLOv8, MediaPipe (action detection)

OpenAI GPT / Llama-3 (caption + commentary)

gTTS / Coqui (voice output)

Flask / Streamlit

ğŸš€ Steps

Extract video frames.

Detect human poses/actions.

Convert detections into structured event list.

Generate description: â€œPerson A runs towards B and throws ball.â€

Convert to audio + overlay on video.
